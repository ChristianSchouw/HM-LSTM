{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DeepLearningProject_LSTM.ipynb","provenance":[{"file_id":"1_F7b-NS12O_XX6cE-F2oZcyidKFHuZLn","timestamp":1575279155608}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"N_nvMfJlmAXh","colab_type":"text"},"source":["# Deep Bioinformatics project"]},{"cell_type":"code","metadata":{"id":"sJFILejsh027","colab_type":"code","colab":{}},"source":["import matplotlib\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import glob\n","import os\n","import torch\n","import pickle as pkl\n","import time\n","from IPython.display import clear_output\n","from skimage.io import imread\n","from skimage.transform import resize\n","from torch.autograd import Variable\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.nn import Linear, GRU, Dropout, BatchNorm1d, LSTM\n","from torch.nn.functional import relu, elu, relu6, sigmoid, tanh, softmax"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gO9Xzj5qllwk","colab_type":"text"},"source":["## data import"]},{"cell_type":"markdown","metadata":{"id":"RZt1sdXI3G6Y","colab_type":"text"},"source":["## Use cuda"]},{"cell_type":"code","metadata":{"id":"sMWLPu3j3K_6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"99821ab2-2717-4859-b0a2-68328d73f591","executionInfo":{"status":"ok","timestamp":1575295684674,"user_tz":-60,"elapsed":3769,"user":{"displayName":"Christian Sørensen","photoUrl":"","userId":"11975872482681044821"}}},"source":["torch.cuda.empty_cache()\n","\n","use_cuda = torch.cuda.is_available()\n","print(\"Running GPU.\") if use_cuda else print(\"No GPU available.\")\n","\n","\n","def get_variable(x):\n","    \"\"\" Converts tensors to cuda, if available. \"\"\"\n","    if use_cuda:\n","        return x.cuda()\n","    return x\n","\n","\n","def get_numpy(x):\n","    \"\"\" Get numpy array for both cuda and not. \"\"\"\n","    if use_cuda:\n","        return x.cpu().data.numpy()\n","    return x.data.numpy()"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Running GPU.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0TB4LjdDa2XF","colab_type":"text"},"source":["## Data (Penn Treebank)"]},{"cell_type":"code","metadata":{"id":"YpZrNjHAbCuY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":104},"outputId":"75c6f122-81bc-4212-daee-2aba7b33928f","executionInfo":{"status":"ok","timestamp":1575296993881,"user_tz":-60,"elapsed":6745,"user":{"displayName":"Christian Sørensen","photoUrl":"","userId":"11975872482681044821"}}},"source":["from torchtext import data\n","from torchtext import datasets\n","from torchtext.vocab import GloVe\n","def tokenize(lines):\n","  return [line for line in lines]\n","# Approach 1:\n","# set up fields\n","TEXT = data.Field(lower=True,tokenize=tokenize, batch_first=True)\n","\n","# make splits for data\n","train, valid, test = datasets.PennTreebank.splits(TEXT)\n","\n","# print information about the data\n","print('train.fields', train.fields)\n","print('len(train)', len(train))\n","print('vars(train[0])', vars(train[0])['text'][0:10])\n","\n","# build the vocabulary\n","TEXT.build_vocab(train, vectors=GloVe(name='6B', dim=300)) # GloVe is a better version of Word2Vec, it is a general thing. \n","# 100 for the dimension of the embedding is suitable. Better not to use GloVe as it is too general\n","# We will do embeddings also with the protein dataset\n","\n","# print vocab information\n","print('len(TEXT.vocab)', len(TEXT.vocab))\n","\n","vars(train[0])['text'] = vars(train[0])['text']\n","vars(valid[0])['text'] = vars(test[0])['text']\n","vars(test[0])['text'] = vars(test[0])['text']\n","# make iterator for splits\n","train_iter, valid_iter, test_iter = data.BPTTIterator.splits(\n","    #(train, valid, test), batch_size=3, bptt_len=30)\n","    (train, valid, test), batch_size=3, bptt_len=50)\n","\n","# batch_size = number of sentences // bptt (back propagation through time) = number of words per sentence\n","\n","# print batch information\n","batch = next(iter(train_iter))\n","print(vars(train[0])['text'][0:10])"],"execution_count":10,"outputs":[{"output_type":"stream","text":["train.fields {'text': <torchtext.data.field.Field object at 0x7fb12a31b128>}\n","len(train) 1\n","vars(train[0]) [' ', 'a', 'e', 'r', ' ', 'b', 'a', 'n', 'k', 'n']\n","len(TEXT.vocab) 51\n","[' ', 'a', 'e', 'r', ' ', 'b', 'a', 'n', 'k', 'n']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"o8ngcxc-ZD5a","colab_type":"text"},"source":["HM_LSTM"]},{"cell_type":"code","metadata":{"id":"sRNoR6oIZEeS","colab_type":"code","colab":{}},"source":["import torch\n","from torch.autograd import Function, Variable\n","import torch.nn.functional as Func\n","from torch.nn import Module, Parameter\n","import math\n","import time\n","import torch.optim as optim\n","import numpy\n","import torch.nn.functional as Func\n","import os\n","#from utils import reverse, batchify, get_batch, repackage_hidden, evaluatePTB\n","\n","hidden_dim = 200\n","vocab_size = len(TEXT.vocab)\n","bptt_len = 30\n","embedding_size = 300\n","out_dim = 500\n","def repackage_hidden(h):\n","    if type(h) == Variable:\n","        return Variable(h.data)\n","    else:\n","        return tuple(repackage_hidden(v) for v in h)\n","def hard_sigm(a, x):\n","    temp = torch.div(torch.add(torch.mul(x, a), 1), 2.0)\n","    output = torch.clamp(temp, min=0, max=1)\n","    return output\n","\n","class bound(Function):\n","    def forward(self, x):\n","        # forward : x -> output\n","        self.save_for_backward(x)\n","        output = x > 0.5\n","        return output.float()\n","\n","    def backward(self, output_grad):\n","        # backward: output_grad -> x_grad\n","        x = self.saved_tensors\n","        x_grad = None\n","\n","        if self.needs_input_grad[0]:\n","            x_grad = output_grad.clone()\n","\n","        return x_grad\n","\n","class masked_NLLLoss(Module):\n","    def __init__(self):\n","        super(masked_NLLLoss, self).__init__()\n","\n","    def forward(self, cost, inputs, mask):\n","        # inputs.size = mask.size = batch_size\n","        # cost.size = batch_size * dict_size\n","\n","        # The following version is too slow, deprecated now\n","        # loss = Variable(torch.zeros(inputs.size(0))).cuda()\n","        # for i in range(inputs.size(0)):\n","        #     loss[i] = - cost[i, inputs[i]] * mask[i]\n","\n","        # The following version is much faster\n","        batch_size, dict_size = cost.size()\n","        cost_flat = cost.view(batch_size*dict_size)\n","        inputs_flat = torch.arange(0, inputs.size(0)).cuda().long()\n","        inputs_flat_idx = torch.mul(inputs_flat, dict_size) + inputs\n","        loss = -cost_flat[inputs_flat_idx] * mask\n","        return loss\n","\n","class HM_LSTMCell(Module):\n","    def __init__(self, bottom_size, hidden_size, top_size, a, last_layer):\n","        super(HM_LSTMCell, self).__init__()\n","        self.bottom_size = bottom_size\n","        self.hidden_size = hidden_size\n","        self.top_size = top_size\n","        self.a = a\n","        self.last_layer = last_layer\n","        '''\n","        U_11 means the state transition parameters from layer l (current layer) to layer l\n","        U_21 means the state transition parameters from layer l+1 (top layer) to layer l\n","        W_01 means the state transition parameters from layer l-1 (bottom layer) to layer l\n","        '''\n","        self.U_11 = Parameter(torch.cuda.FloatTensor(4 * self.hidden_size + 1, self.hidden_size))\n","        if not self.last_layer:\n","            self.U_21 = Parameter(torch.cuda.FloatTensor(4 * self.hidden_size + 1, self.top_size))\n","        self.W_01 = Parameter(torch.cuda.FloatTensor(4 * self.hidden_size + 1, self.bottom_size))\n","        self.bias = Parameter(torch.cuda.FloatTensor(4 * self.hidden_size + 1))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        stdv = 1.0 / math.sqrt(self.hidden_size)\n","        for par in self.parameters():\n","            par.data.uniform_(-stdv, stdv)\n","\n","    def forward(self, c, h_bottom, h, h_top, z, z_bottom):\n","        # h_bottom.size = bottom_size * batch_size\n","        s_recur = torch.mm(self.W_01, h_bottom)\n","        if not self.last_layer:\n","            s_topdown_ = torch.mm(self.U_21, h_top)\n","            s_topdown = z.expand_as(s_topdown_) * s_topdown_\n","        else:\n","            s_topdown = Variable(torch.zeros(s_recur.size()).cuda(), requires_grad=False).cuda()\n","        s_bottomup_ = torch.mm(self.U_11, h)\n","        s_bottomup = z_bottom.expand_as(s_bottomup_) * s_bottomup_\n","\n","        f_s = s_recur + s_topdown + s_bottomup + self.bias.unsqueeze(1).expand_as(s_recur)\n","        # f_s.size = (4 * hidden_size + 1) * batch_size\n","        f = Func.sigmoid(f_s[0:self.hidden_size, :])  # hidden_size * batch_size\n","        i = Func.sigmoid(f_s[self.hidden_size:self.hidden_size*2, :])\n","        o = Func.sigmoid(f_s[self.hidden_size*2:self.hidden_size*3, :])\n","        g = Func.tanh(f_s[self.hidden_size*3:self.hidden_size*4, :])\n","        z_hat = hard_sigm(self.a, f_s[self.hidden_size*4:self.hidden_size*4+1, :])\n","\n","        one = Variable(torch.ones(f.size()).cuda(), requires_grad=False)\n","        z = z.expand_as(f)\n","        z_bottom = z_bottom.expand_as(f)\n","\n","        c_new = z * (i * g) + (one - z) * (one - z_bottom) * c + (one - z) * z_bottom * (f * c + i * g)\n","        h_new = z * o * Func.tanh(c_new) + (one - z) * (one - z_bottom) * h + (one - z) * z_bottom * o * Func.tanh(c_new)\n","\n","        # if z == 1: (FLUSH)\n","        #     c_new = i * g\n","        #     h_new = o * Func.tanh(c_new)\n","        # elif z_bottom == 0: (COPY)\n","        #     c_new = c\n","        #     h_new = h\n","        # else: (UPDATE)\n","        #     c_new = f * c + i * g\n","        #     h_new = o * Func.tanh(c_new)\n","\n","        z_new = bound()(z_hat)\n","\n","        return h_new, c_new, z_new\n","\n","\n","class HM_LSTM(Module):\n","    def __init__(self, a, input_size, size_list):\n","        super(HM_LSTM, self).__init__()\n","        self.a = a\n","        self.input_size = input_size\n","        self.size_list = size_list\n","\n","        self.cell_1 = HM_LSTMCell(self.input_size, self.size_list[0], self.size_list[1], self.a, False)\n","        self.cell_2 = HM_LSTMCell(self.size_list[0], self.size_list[1], None, self.a, True)\n","\n","    def forward(self, inputs, hidden):\n","        # inputs.size = (batch_size, time steps, embed_size/input_size)\n","        time_steps = inputs.size(1)\n","        batch_size = inputs.size(0)\n","\n","        if hidden == None:\n","            h_t1 = Variable(torch.zeros(self.size_list[0], batch_size).float().cuda(), requires_grad=False)\n","            c_t1 = Variable(torch.zeros(self.size_list[0], batch_size).float().cuda(), requires_grad=False)\n","            z_t1 = Variable(torch.zeros(1, batch_size).float().cuda(), requires_grad=False)\n","            h_t2 = Variable(torch.zeros(self.size_list[1], batch_size).float().cuda(), requires_grad=False)\n","            c_t2 = Variable(torch.zeros(self.size_list[1], batch_size).float().cuda(), requires_grad=False)\n","            z_t2 = Variable(torch.zeros(1, batch_size).float().cuda(), requires_grad=False)\n","        else:\n","            (h_t1, c_t1, z_t1, h_t2, c_t2, z_t2) = hidden\n","        z_one = Variable(torch.ones(1, batch_size).float().cuda(), requires_grad=False)\n","\n","        h_1 = []\n","        h_2 = []\n","        z_1 = []\n","        z_2 = []\n","        for t in range(time_steps):\n","            h_t1, c_t1, z_t1 = self.cell_1(c=c_t1, h_bottom=inputs[:, t, :].t(), h=h_t1, h_top=h_t2, z=z_t1, z_bottom=z_one)\n","            h_t2, c_t2, z_t2 = self.cell_2(c=c_t2, h_bottom=h_t1, h=h_t2, h_top=None, z=z_t2, z_bottom=z_t1)  # 0.01s used\n","            h_1 += [h_t1.t()]\n","            h_2 += [h_t2.t()]\n","            z_1 += [z_t1.t()]\n","            z_2 += [z_t2.t()]\n","\n","        hidden = (h_t1, c_t1, z_t1, h_t2, c_t2, z_t2)\n","        return torch.stack(h_1, dim=1), torch.stack(h_2, dim=1), torch.stack(z_1, dim=1), torch.stack(z_2, dim=1), hidden\n","\n","class HM_Net(Module):\n","    def __init__(self, a, size_list, dict_size, embed_size):\n","        super(HM_Net, self).__init__()\n","        self.dict_size = dict_size\n","        self.size_list = size_list\n","        self.drop = nn.Dropout(p=0.5)\n","        self.embed_in = nn.Embedding(dict_size, embed_size)\n","        self.HM_LSTM = HM_LSTM(a, embed_size, size_list)\n","        self.weight = nn.Linear(size_list[0]+size_list[1], 2)\n","        self.embed_out1 = nn.Linear(size_list[0], dict_size)\n","        self.embed_out2 = nn.Linear(size_list[1], dict_size)\n","        self.relu = nn.ReLU()\n","        # self.logsoftmax = nn.LogSoftmax()\n","        # self.loss = masked_NLLLoss()\n","        self.loss = nn.CrossEntropyLoss()\n","\n","    def forward(self, inputs, target, hidden):\n","        # inputs : batch_size * time_steps\n","        # mask : batch_size * time_steps\n","\n","        emb = self.embed_in(Variable(inputs, volatile=not self.training))  # batch_size * time_steps * embed_size\n","        emb = self.drop(emb)\n","        h_1, h_2, z_1, z_2, hidden = self.HM_LSTM(emb, hidden)  # batch_size * time_steps * hidden_size\n","\n","        # mask = Variable(mask, requires_grad=False)\n","        # batch_loss = Variable(torch.zeros(batch_size).cuda())\n","\n","        h_1 = self.drop(h_1)  # batch_size * time_steps * hidden_size\n","        h_2 = self.drop(h_2)\n","        h = torch.cat((h_1, h_2), 2)\n","\n","        g = Func.sigmoid(self.weight(h.view(h.size(0)*h.size(1), h.size(2))))\n","        g_1 = g[:, 0:1]  # batch_size * time_steps, 1\n","        g_2 = g[:, 1:2]\n","\n","        h_e1 = g_1.expand(g_1.size(0), self.dict_size)*self.embed_out1(h_1.view(h_1.size(0)*h_1.size(1), h_2.size(2)))\n","        h_e2 = g_2.expand(g_2.size(0), self.dict_size)*self.embed_out2(h_2.view(h_2.size(0)*h_2.size(1), h_2.size(2)))\n","\n","        h_e = self.relu(h_e1 + h_e2)  # batch_size*time_steps, hidden_size\n","        # target = target.view(-1).type(torch.cuda.LongTensor)\n","        batch_loss = self.loss(h_e, Variable(target))\n","\n","        return batch_loss, hidden, z_1, z_2\n","\n","    def init_hidden(self, batch_size):\n","        h_t1 = Variable(torch.zeros(self.size_list[0], batch_size).float().cuda(), requires_grad=False)\n","        c_t1 = Variable(torch.zeros(self.size_list[0], batch_size).float().cuda(), requires_grad=False)\n","        z_t1 = Variable(torch.zeros(1, batch_size).float().cuda(), requires_grad=False)\n","        h_t2 = Variable(torch.zeros(self.size_list[1], batch_size).float().cuda(), requires_grad=False)\n","        c_t2 = Variable(torch.zeros(self.size_list[1], batch_size).float().cuda(), requires_grad=False)\n","        z_t2 = Variable(torch.zeros(1, batch_size).float().cuda(), requires_grad=False)\n","\n","        hidden = (h_t1, c_t1, z_t1, h_t2, c_t2, z_t2)\n","        return hidden\n","\n","#net = HM_Net(0.5,[200,200],vocab_size, embedding_size)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mGWeZ7CoVtbZ","colab_type":"text"},"source":["## LSTM"]},{"cell_type":"code","metadata":{"id":"KSo3nHUNVT9c","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":156},"outputId":"62b819d3-85f3-49de-e211-1a993992c99c","executionInfo":{"status":"ok","timestamp":1575297001084,"user_tz":-60,"elapsed":1036,"user":{"displayName":"Christian Sørensen","photoUrl":"","userId":"11975872482681044821"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","hidden_dim = 200\n","vocab_size = len(TEXT.vocab)\n","bptt_len = 30\n","embedding_size = 300\n","out_dim = 500\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        \n","        # Embedding layer\n","        self.embedding = nn.Embedding(vocab_size, embedding_size) #vocab size, vector size\n","        \n","        # Recurrent layer\n","        self.lstm = nn.LSTM(input_size = embedding_size,\n","                           hidden_size = hidden_dim)\n","        self.Dropout = nn.Dropout(0.2)\n","        # Output layer\n","\n","        self.ff = nn.Linear(in_features = hidden_dim,\n","                            out_features = out_dim,\n","                            bias=False)\n","        self.l_out = nn.Linear(in_features = hidden_dim,\n","                            out_features = vocab_size,\n","                            bias=False)\n","        \n","        self.batchnorm = nn.BatchNorm1d(num_features=hidden_dim)\n","\n","        #emb = embedded_dropout(self.encoder, input, dropout=self.dropoute if self.training else 0)\n","        #emb = self.idrop(emb)\n","        #emb = self.lockdrop(emb, self.dropouti)\n","\n","    def forward(self, x):\n","        x = x.cuda()\n","        x = self.embedding(x)\n","\n","        # RNN returns output and last hidden state\n","\n","        x, (h, c) = self.lstm(x)\n","        \n","\n","        # Flatten output for feed-forward layer\n","        x = x.view(-1, self.lstm.hidden_size)\n","\n","        x = self.batchnorm(x)\n","\n","        #x = self.ff(x)\n","        #x = self.Dropout(x)\n","        #x = relu(x)\n","        x = self.l_out(x)\n","        #x = relu(x)\n","\n","        return x\n","\n","net = Net()\n","print(net)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Net(\n","  (embedding): Embedding(51, 300)\n","  (lstm): LSTM(300, 200)\n","  (Dropout): Dropout(p=0.2, inplace=False)\n","  (ff): Linear(in_features=200, out_features=500, bias=False)\n","  (l_out): Linear(in_features=200, out_features=51, bias=False)\n","  (batchnorm): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FQlYosG1V7iN","colab_type":"text"},"source":["## Training loop"]},{"cell_type":"code","metadata":{"id":"ehjt8tduV7HR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"d42b2336-831c-42c6-e768-f1979da8dd6e","executionInfo":{"status":"ok","timestamp":1575300590968,"user_tz":-60,"elapsed":3587076,"user":{"displayName":"Christian Sørensen","photoUrl":"","userId":"11975872482681044821"}}},"source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","import torch.optim as optim\n","\n","# Train with cross entropy and at the end evaluate perplexity, similar to an accuracy measure\n","\n","# Hyper-parameters\n","num_epochs = 10\n","batch_size = 32\n","# Initialize a new network\n","net = Net()\n","net = net.cuda()\n","\n","# Define a loss function and optimizer for this problem\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(net.parameters(), lr=0.0003) # ,weight_decay=0.001)\n","#optimizer = optim.SGD(net.parameters(), lr=0.00001)\n","\n","# Track loss\n","training_loss, validation_loss, BPC = [], [], []\n","\n","# For each epoch\n","for i in range(num_epochs):\n","    # Track loss\n","    epoch_training_loss = 0\n","    epoch_validation_loss = 0\n","        \n","    # For each sentence in validation set\n","    valid_sum=0\n","    net.eval()\n","    # print(hidden)\n","    for j,batch in enumerate(valid_iter):\n","        if j % 1000 ==0:\n","          print(\"batch: \", j , \"out of \", len(valid_iter))\n","        text = batch.text.cuda()\n","        target = batch.target.cuda()\n","        # Forward pass\n","\n","        \n","        outputs = net(text)\n","        \n","        target = target.view(-1).type(torch.cuda.LongTensor)\n","        loss = criterion(outputs, target)\n","\n","        # Update loss\n","        epoch_validation_loss += loss.detach().cpu().data.numpy()\n","\n","\n","        #valid_sum+=loss\n","    \n","    net.train()\n","    # For each sentence in training set\n","    for j,batch in enumerate(train_iter):\n","        if j % 1000 ==0:\n","          print(\"batch: \", j, \"out of \", len(train_iter))\n","        text = batch.text.cuda()\n","        target = batch.target.cuda()\n","                \n","        # Forward pass\n","        #text = text.t()\n","        target = target.view(-1).type(torch.cuda.LongTensor)\n","        outputs = net(text)\n","        \n","        # Compute loss\n","        loss = criterion(outputs, target)\n","        \n","        # Backward pass\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        # Update loss\n","        epoch_training_loss += loss.detach().cpu().data.numpy()\n","\n","    \n","    # Save loss for plot\n","    training_loss.append(epoch_training_loss/len(train_iter))\n","    validation_loss.append(epoch_validation_loss/len(valid_iter))\n","\n","    # Print loss every 5 epochs\n","    \n","    print(f'Epoch {i}, training loss: {training_loss[-1]}, validation loss: {validation_loss[-1]}')\n","\n","# Get first sentence in test set\n","#text, target = test_iter[1]\n","\n","# One-hot encode input and target sequence\n","# inputs_one_hot = one_hot_encode_sequence(inputs, vocab_size)\n","# targets_idx = [word_to_idx[word] for word in targets]\n","\n","# Convert input to tensor\n","# inputs_one_hot = torch.Tensor(inputs_one_hot)\n","# inputs_one_hot = inputs_one_hot.permute(0, 2, 1)\n","\n","# Convert target to tensor\n","# targets_idx = torch.LongTensor(targets_idx)\n","\n","# Forward pass\n","# outputs = net.forward(text).cpu().data.numpy()\n","\n","#print('\\nInput sequence:')\n","#print(text)\n","\n","#print('\\nTarget sequence:')\n","#print(target)\n","\n","#print('\\nPredicted sequence:')\n","#print([idx_to_word[np.argmax(output)] for output in outputs])\n","\n","# Plot training and validation loss\n","epoch = np.arange(len(training_loss))\n","plt.figure()\n","plt.plot(epoch, training_loss, 'r', label='Training loss',)\n","plt.plot(epoch, validation_loss, 'b', label='Validation loss')\n","plt.legend()\n","plt.xlabel('Epoch'), plt.ylabel('NLL')\n","plt.show()"],"execution_count":12,"outputs":[{"output_type":"stream","text":["batch:  0 out of  3000\n","batch:  1000 out of  3000\n","batch:  2000 out of  3000\n","batch:  0 out of  34011\n","batch:  1000 out of  34011\n","batch:  2000 out of  34011\n","batch:  3000 out of  34011\n","batch:  4000 out of  34011\n","batch:  5000 out of  34011\n","batch:  6000 out of  34011\n","batch:  7000 out of  34011\n","batch:  8000 out of  34011\n","batch:  9000 out of  34011\n","batch:  10000 out of  34011\n","batch:  11000 out of  34011\n","batch:  12000 out of  34011\n","batch:  13000 out of  34011\n","batch:  14000 out of  34011\n","batch:  15000 out of  34011\n","batch:  16000 out of  34011\n","batch:  17000 out of  34011\n","batch:  18000 out of  34011\n","batch:  19000 out of  34011\n","batch:  20000 out of  34011\n","batch:  21000 out of  34011\n","batch:  22000 out of  34011\n","batch:  23000 out of  34011\n","batch:  24000 out of  34011\n","batch:  25000 out of  34011\n","batch:  26000 out of  34011\n","batch:  27000 out of  34011\n","batch:  28000 out of  34011\n","batch:  29000 out of  34011\n","batch:  30000 out of  34011\n","batch:  31000 out of  34011\n","batch:  32000 out of  34011\n","batch:  33000 out of  34011\n","batch:  34000 out of  34011\n","Epoch 0, training loss: 1.3427844674840101, validation loss: 3.9278956755797068\n","batch:  0 out of  3000\n","batch:  1000 out of  3000\n","batch:  2000 out of  3000\n","batch:  0 out of  34011\n","batch:  1000 out of  34011\n","batch:  2000 out of  34011\n","batch:  3000 out of  34011\n","batch:  4000 out of  34011\n","batch:  5000 out of  34011\n","batch:  6000 out of  34011\n","batch:  7000 out of  34011\n","batch:  8000 out of  34011\n","batch:  9000 out of  34011\n","batch:  10000 out of  34011\n","batch:  11000 out of  34011\n","batch:  12000 out of  34011\n","batch:  13000 out of  34011\n","batch:  14000 out of  34011\n","batch:  15000 out of  34011\n","batch:  16000 out of  34011\n","batch:  17000 out of  34011\n","batch:  18000 out of  34011\n","batch:  19000 out of  34011\n","batch:  20000 out of  34011\n","batch:  21000 out of  34011\n","batch:  22000 out of  34011\n","batch:  23000 out of  34011\n","batch:  24000 out of  34011\n","batch:  25000 out of  34011\n","batch:  26000 out of  34011\n","batch:  27000 out of  34011\n","batch:  28000 out of  34011\n","batch:  29000 out of  34011\n","batch:  30000 out of  34011\n","batch:  31000 out of  34011\n","batch:  32000 out of  34011\n","batch:  33000 out of  34011\n","batch:  34000 out of  34011\n","Epoch 1, training loss: 1.1669400311540525, validation loss: 1.3017984153827031\n","batch:  0 out of  3000\n","batch:  1000 out of  3000\n","batch:  2000 out of  3000\n","batch:  0 out of  34011\n","batch:  1000 out of  34011\n","batch:  2000 out of  34011\n","batch:  3000 out of  34011\n","batch:  4000 out of  34011\n","batch:  5000 out of  34011\n","batch:  6000 out of  34011\n","batch:  7000 out of  34011\n","batch:  8000 out of  34011\n","batch:  9000 out of  34011\n","batch:  10000 out of  34011\n","batch:  11000 out of  34011\n","batch:  12000 out of  34011\n","batch:  13000 out of  34011\n","batch:  14000 out of  34011\n","batch:  15000 out of  34011\n","batch:  16000 out of  34011\n","batch:  17000 out of  34011\n","batch:  18000 out of  34011\n","batch:  19000 out of  34011\n","batch:  20000 out of  34011\n","batch:  21000 out of  34011\n","batch:  22000 out of  34011\n","batch:  23000 out of  34011\n","batch:  24000 out of  34011\n","batch:  25000 out of  34011\n","batch:  26000 out of  34011\n","batch:  27000 out of  34011\n","batch:  28000 out of  34011\n","batch:  29000 out of  34011\n","batch:  30000 out of  34011\n","batch:  31000 out of  34011\n","batch:  32000 out of  34011\n","batch:  33000 out of  34011\n","batch:  34000 out of  34011\n","Epoch 2, training loss: 1.1174551974528013, validation loss: 1.2514836269219716\n","batch:  0 out of  3000\n","batch:  1000 out of  3000\n","batch:  2000 out of  3000\n","batch:  0 out of  34011\n","batch:  1000 out of  34011\n","batch:  2000 out of  34011\n","batch:  3000 out of  34011\n","batch:  4000 out of  34011\n","batch:  5000 out of  34011\n","batch:  6000 out of  34011\n","batch:  7000 out of  34011\n","batch:  8000 out of  34011\n","batch:  9000 out of  34011\n","batch:  10000 out of  34011\n","batch:  11000 out of  34011\n","batch:  12000 out of  34011\n","batch:  13000 out of  34011\n","batch:  14000 out of  34011\n","batch:  15000 out of  34011\n","batch:  16000 out of  34011\n","batch:  17000 out of  34011\n","batch:  18000 out of  34011\n","batch:  19000 out of  34011\n","batch:  20000 out of  34011\n","batch:  21000 out of  34011\n","batch:  22000 out of  34011\n","batch:  23000 out of  34011\n","batch:  24000 out of  34011\n","batch:  25000 out of  34011\n","batch:  26000 out of  34011\n","batch:  27000 out of  34011\n","batch:  28000 out of  34011\n","batch:  29000 out of  34011\n","batch:  30000 out of  34011\n","batch:  31000 out of  34011\n","batch:  32000 out of  34011\n","batch:  33000 out of  34011\n","batch:  34000 out of  34011\n","Epoch 3, training loss: 1.0889141741651651, validation loss: 1.224950120349725\n","batch:  0 out of  3000\n","batch:  1000 out of  3000\n","batch:  2000 out of  3000\n","batch:  0 out of  34011\n","batch:  1000 out of  34011\n","batch:  2000 out of  34011\n","batch:  3000 out of  34011\n","batch:  4000 out of  34011\n","batch:  5000 out of  34011\n","batch:  6000 out of  34011\n","batch:  7000 out of  34011\n","batch:  8000 out of  34011\n","batch:  9000 out of  34011\n","batch:  10000 out of  34011\n","batch:  11000 out of  34011\n","batch:  12000 out of  34011\n","batch:  13000 out of  34011\n","batch:  14000 out of  34011\n","batch:  15000 out of  34011\n","batch:  16000 out of  34011\n","batch:  17000 out of  34011\n","batch:  18000 out of  34011\n","batch:  19000 out of  34011\n","batch:  20000 out of  34011\n","batch:  21000 out of  34011\n","batch:  22000 out of  34011\n","batch:  23000 out of  34011\n","batch:  24000 out of  34011\n","batch:  25000 out of  34011\n","batch:  26000 out of  34011\n","batch:  27000 out of  34011\n","batch:  28000 out of  34011\n","batch:  29000 out of  34011\n","batch:  30000 out of  34011\n","batch:  31000 out of  34011\n","batch:  32000 out of  34011\n","batch:  33000 out of  34011\n","batch:  34000 out of  34011\n","Epoch 4, training loss: 1.0692766375642773, validation loss: 1.2075101915399233\n","batch:  0 out of  3000\n","batch:  1000 out of  3000\n","batch:  2000 out of  3000\n","batch:  0 out of  34011\n","batch:  1000 out of  34011\n","batch:  2000 out of  34011\n","batch:  3000 out of  34011\n","batch:  4000 out of  34011\n","batch:  5000 out of  34011\n","batch:  6000 out of  34011\n","batch:  7000 out of  34011\n","batch:  8000 out of  34011\n","batch:  9000 out of  34011\n","batch:  10000 out of  34011\n","batch:  11000 out of  34011\n","batch:  12000 out of  34011\n","batch:  13000 out of  34011\n","batch:  14000 out of  34011\n","batch:  15000 out of  34011\n","batch:  16000 out of  34011\n","batch:  17000 out of  34011\n","batch:  18000 out of  34011\n","batch:  19000 out of  34011\n","batch:  20000 out of  34011\n","batch:  21000 out of  34011\n","batch:  22000 out of  34011\n","batch:  23000 out of  34011\n","batch:  24000 out of  34011\n","batch:  25000 out of  34011\n","batch:  26000 out of  34011\n","batch:  27000 out of  34011\n","batch:  28000 out of  34011\n","batch:  29000 out of  34011\n","batch:  30000 out of  34011\n","batch:  31000 out of  34011\n","batch:  32000 out of  34011\n","batch:  33000 out of  34011\n","batch:  34000 out of  34011\n","Epoch 5, training loss: 1.05454435244692, validation loss: 1.1962737030585606\n","batch:  0 out of  3000\n","batch:  1000 out of  3000\n","batch:  2000 out of  3000\n","batch:  0 out of  34011\n","batch:  1000 out of  34011\n","batch:  2000 out of  34011\n","batch:  3000 out of  34011\n","batch:  4000 out of  34011\n","batch:  5000 out of  34011\n","batch:  6000 out of  34011\n","batch:  7000 out of  34011\n","batch:  8000 out of  34011\n","batch:  9000 out of  34011\n","batch:  10000 out of  34011\n","batch:  11000 out of  34011\n","batch:  12000 out of  34011\n","batch:  13000 out of  34011\n","batch:  14000 out of  34011\n","batch:  15000 out of  34011\n","batch:  16000 out of  34011\n","batch:  17000 out of  34011\n","batch:  18000 out of  34011\n","batch:  19000 out of  34011\n","batch:  20000 out of  34011\n","batch:  21000 out of  34011\n","batch:  22000 out of  34011\n","batch:  23000 out of  34011\n","batch:  24000 out of  34011\n","batch:  25000 out of  34011\n","batch:  26000 out of  34011\n","batch:  27000 out of  34011\n","batch:  28000 out of  34011\n","batch:  29000 out of  34011\n","batch:  30000 out of  34011\n","batch:  31000 out of  34011\n","batch:  32000 out of  34011\n","batch:  33000 out of  34011\n","batch:  34000 out of  34011\n","Epoch 6, training loss: 1.0428793659188755, validation loss: 1.187750118335088\n","batch:  0 out of  3000\n","batch:  1000 out of  3000\n","batch:  2000 out of  3000\n","batch:  0 out of  34011\n","batch:  1000 out of  34011\n","batch:  2000 out of  34011\n","batch:  3000 out of  34011\n","batch:  4000 out of  34011\n","batch:  5000 out of  34011\n","batch:  6000 out of  34011\n","batch:  7000 out of  34011\n","batch:  8000 out of  34011\n","batch:  9000 out of  34011\n","batch:  10000 out of  34011\n","batch:  11000 out of  34011\n","batch:  12000 out of  34011\n","batch:  13000 out of  34011\n","batch:  14000 out of  34011\n","batch:  15000 out of  34011\n","batch:  16000 out of  34011\n","batch:  17000 out of  34011\n","batch:  18000 out of  34011\n","batch:  19000 out of  34011\n","batch:  20000 out of  34011\n","batch:  21000 out of  34011\n","batch:  22000 out of  34011\n","batch:  23000 out of  34011\n","batch:  24000 out of  34011\n","batch:  25000 out of  34011\n","batch:  26000 out of  34011\n","batch:  27000 out of  34011\n","batch:  28000 out of  34011\n","batch:  29000 out of  34011\n","batch:  30000 out of  34011\n","batch:  31000 out of  34011\n","batch:  32000 out of  34011\n","batch:  33000 out of  34011\n","batch:  34000 out of  34011\n","Epoch 7, training loss: 1.033415212365475, validation loss: 1.181604527870814\n","batch:  0 out of  3000\n","batch:  1000 out of  3000\n","batch:  2000 out of  3000\n","batch:  0 out of  34011\n","batch:  1000 out of  34011\n","batch:  2000 out of  34011\n","batch:  3000 out of  34011\n","batch:  4000 out of  34011\n","batch:  5000 out of  34011\n","batch:  6000 out of  34011\n","batch:  7000 out of  34011\n","batch:  8000 out of  34011\n","batch:  9000 out of  34011\n","batch:  10000 out of  34011\n","batch:  11000 out of  34011\n","batch:  12000 out of  34011\n","batch:  13000 out of  34011\n","batch:  14000 out of  34011\n","batch:  15000 out of  34011\n","batch:  16000 out of  34011\n","batch:  17000 out of  34011\n","batch:  18000 out of  34011\n","batch:  19000 out of  34011\n","batch:  20000 out of  34011\n","batch:  21000 out of  34011\n","batch:  22000 out of  34011\n","batch:  23000 out of  34011\n","batch:  24000 out of  34011\n","batch:  25000 out of  34011\n","batch:  26000 out of  34011\n","batch:  27000 out of  34011\n","batch:  28000 out of  34011\n","batch:  29000 out of  34011\n","batch:  30000 out of  34011\n","batch:  31000 out of  34011\n","batch:  32000 out of  34011\n","batch:  33000 out of  34011\n","batch:  34000 out of  34011\n","Epoch 8, training loss: 1.0255671258496508, validation loss: 1.1770049125154813\n","batch:  0 out of  3000\n","batch:  1000 out of  3000\n","batch:  2000 out of  3000\n","batch:  0 out of  34011\n","batch:  1000 out of  34011\n","batch:  2000 out of  34011\n","batch:  3000 out of  34011\n","batch:  4000 out of  34011\n","batch:  5000 out of  34011\n","batch:  6000 out of  34011\n","batch:  7000 out of  34011\n","batch:  8000 out of  34011\n","batch:  9000 out of  34011\n","batch:  10000 out of  34011\n","batch:  11000 out of  34011\n","batch:  12000 out of  34011\n","batch:  13000 out of  34011\n","batch:  14000 out of  34011\n","batch:  15000 out of  34011\n","batch:  16000 out of  34011\n","batch:  17000 out of  34011\n","batch:  18000 out of  34011\n","batch:  19000 out of  34011\n","batch:  20000 out of  34011\n","batch:  21000 out of  34011\n","batch:  22000 out of  34011\n","batch:  23000 out of  34011\n","batch:  24000 out of  34011\n","batch:  25000 out of  34011\n","batch:  26000 out of  34011\n","batch:  27000 out of  34011\n","batch:  28000 out of  34011\n","batch:  29000 out of  34011\n","batch:  30000 out of  34011\n","batch:  31000 out of  34011\n","batch:  32000 out of  34011\n","batch:  33000 out of  34011\n","batch:  34000 out of  34011\n","Epoch 9, training loss: 1.0188916276481326, validation loss: 1.1731701837380728\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"QYvpKOC-gDll","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":295},"outputId":"2a1f050e-a29e-4052-df3a-d9b97d6431db","executionInfo":{"status":"ok","timestamp":1575301002293,"user_tz":-60,"elapsed":4897,"user":{"displayName":"Christian Sørensen","photoUrl":"","userId":"11975872482681044821"}}},"source":["!nvidia-smi"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Mon Dec  2 15:36:34 2019       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.33.01    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   57C    P0    60W / 149W |   6708MiB / 11441MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fcB5NMargFt7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"27fedf47-c0ce-44db-e1f5-1cd4062c01de","executionInfo":{"status":"ok","timestamp":1575300977966,"user_tz":-60,"elapsed":10059,"user":{"displayName":"Christian Sørensen","photoUrl":"","userId":"11975872482681044821"}}},"source":["# For each sentence in test set\n","test_sum=0\n","for j,batch in enumerate(test_iter):\n","    text = batch.text.cuda()\n","    target = batch.target.cuda()\n","    \n","    # Forward pass\n","    target = target.view(-1).type(torch.cuda.LongTensor)\n","    outputs = net(text)\n","\n","\n","\n","    # Compute loss\n","    loss = criterion(outputs, target)\n","    \n","    # calculate softmax BPC\n","    #m = target.shape[0]\n","    #p = softmax(outputs.detach().cpu().data.numpy())\n","    #log_likelihood = -np.log2(p[range(m),target.detach().cpu().data.numpy()])\n","    #loss = np.sum(log_likelihood) / m\n","\n","    test_sum += loss/np.log(2)\n","\n","mean_sum=test_sum/len(test_iter)\n","\n","BPC.append(mean_sum)\n","print(f'Epoch {i}, BPC: {BPC[-1]}')"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Epoch 9, BPC: 1.529180645942688\n"],"name":"stdout"}]}]}